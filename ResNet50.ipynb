{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xETSS1YXaK2m",
        "outputId": "32cd9b1a-67b8-4a2d-d495-836858fa4647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jul  3 05:43:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3c7-hU0aOLH",
        "outputId": "66370a95-64ec-41db-ea47-aec917bed6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkCQoVEh6Xsk",
        "outputId": "16891236-ba87-4f27-b5c7-dd37880d177e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-resnet\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.10/dist-packages (from keras-resnet) (2.12.0)\n",
            "Building wheels for collected packages: keras-resnet\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20459 sha256=2bd88a1c6f5092f6825957f142cf103819d6ffb21225a820c69467896161956b\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/af/88/a668b279c5eadbe55dcaf6207f09059135166cefb09088bacc\n",
            "Successfully built keras-resnet\n",
            "Installing collected packages: keras-resnet\n",
            "Successfully installed keras-resnet-0.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ0o_OfcaZ6V"
      },
      "outputs": [],
      "source": [
        "from keras_resnet.models import ResNet50\n",
        "from keras.models import Model\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHWrSJPHaaCO",
        "outputId": "7ad5aa7e-c1d7-4c37-a7e9-dd50c5c5ec33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 100352)       0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            401412      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,989,124\n",
            "Trainable params: 401,412\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Loading deep learning algorithm\n",
        "from tensorflow import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import keras\n",
        "#import keras.backend as K\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "IMAGE_SIZE = [224,224]\n",
        "CLASS=4\n",
        "inception = tensorflow.keras.applications.ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "#model = ResNet50(weights='imagenet', include_top=False)\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False\n",
        "#folders = glob('C:\\rafid\\guava disease research\\k_guava\\train_image/*')\n",
        "x = Flatten()(inception.output)\n",
        "prediction = Dense(CLASS, activation='softmax')(x)\n",
        "model = Model(inputs=inception.input, outputs=prediction)\n",
        "adam = keras.optimizers.Adam(lr = 0.001)\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer = adam,\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQw6eyxHaaFy",
        "outputId": "caa14267-dc31-45b1-c7a8-3feb731a8451"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "val_set = val_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/val',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/test',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'categorical')\n",
        "print(\"\\n\\n\")\n",
        "model.optimizer.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bigtWDUaaIe",
        "outputId": "f14f61c2-e15e-4a83-f53c-ff3fae7a6a2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-688ef90d70b0>:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  r = model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.5169 - accuracy: 0.2959 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.35754, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.29592, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 2104s 21s/step - loss: 2.5169 - accuracy: 0.2959 - val_loss: 1.3487 - val_accuracy: 0.3575\n",
            "Epoch 2/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.5065 - accuracy: 0.3734\n",
            "Epoch 2: val_accuracy did not improve from 0.35754\n",
            "\n",
            "Epoch 2: accuracy improved from 0.29592 to 0.37341, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 80s 815ms/step - loss: 1.5065 - accuracy: 0.3734 - val_loss: 1.5554 - val_accuracy: 0.2894\n",
            "Epoch 3/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.5787 - accuracy: 0.3760\n",
            "Epoch 3: val_accuracy improved from 0.35754 to 0.37095, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.37341 to 0.37596, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 81s 829ms/step - loss: 1.5787 - accuracy: 0.3760 - val_loss: 1.4173 - val_accuracy: 0.3709\n",
            "Epoch 4/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.5539 - accuracy: 0.4085\n",
            "Epoch 4: val_accuracy improved from 0.37095 to 0.42682, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.37596 to 0.40848, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 81s 827ms/step - loss: 1.5539 - accuracy: 0.4085 - val_loss: 1.2615 - val_accuracy: 0.4268\n",
            "Epoch 5/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.7216 - accuracy: 0.3976\n",
            "Epoch 5: val_accuracy improved from 0.42682 to 0.43911, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.40848\n",
            "98/98 [==============================] - 80s 814ms/step - loss: 1.7216 - accuracy: 0.3976 - val_loss: 1.3528 - val_accuracy: 0.4391\n",
            "Epoch 6/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.4807 - accuracy: 0.4247\n",
            "Epoch 6: val_accuracy did not improve from 0.43911\n",
            "\n",
            "Epoch 6: accuracy improved from 0.40848 to 0.42474, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 80s 814ms/step - loss: 1.4807 - accuracy: 0.4247 - val_loss: 1.5198 - val_accuracy: 0.3855\n",
            "Epoch 7/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2738 - accuracy: 0.4688\n",
            "Epoch 7: val_accuracy improved from 0.43911 to 0.52626, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 7: accuracy improved from 0.42474 to 0.46875, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 82s 838ms/step - loss: 1.2738 - accuracy: 0.4688 - val_loss: 1.1477 - val_accuracy: 0.5263\n",
            "Epoch 8/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.4933\n",
            "Epoch 8: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 8: accuracy improved from 0.46875 to 0.49330, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 80s 816ms/step - loss: 1.1952 - accuracy: 0.4933 - val_loss: 1.3187 - val_accuracy: 0.4648\n",
            "Epoch 9/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.4033 - accuracy: 0.4563\n",
            "Epoch 9: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.49330\n",
            "98/98 [==============================] - 78s 792ms/step - loss: 1.4033 - accuracy: 0.4563 - val_loss: 1.8402 - val_accuracy: 0.3642\n",
            "Epoch 10/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2445 - accuracy: 0.5108\n",
            "Epoch 10: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 10: accuracy improved from 0.49330 to 0.51084, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 79s 811ms/step - loss: 1.2445 - accuracy: 0.5108 - val_loss: 1.1375 - val_accuracy: 0.5128\n",
            "Epoch 11/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.3826 - accuracy: 0.4758\n",
            "Epoch 11: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.51084\n",
            "98/98 [==============================] - 78s 795ms/step - loss: 1.3826 - accuracy: 0.4758 - val_loss: 1.7559 - val_accuracy: 0.4425\n",
            "Epoch 12/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.3157 - accuracy: 0.4876\n",
            "Epoch 12: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.51084\n",
            "98/98 [==============================] - 78s 798ms/step - loss: 1.3157 - accuracy: 0.4876 - val_loss: 1.1668 - val_accuracy: 0.4849\n",
            "Epoch 13/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2544 - accuracy: 0.5121\n",
            "Epoch 13: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 13: accuracy improved from 0.51084 to 0.51212, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 80s 813ms/step - loss: 1.2544 - accuracy: 0.5121 - val_loss: 1.5059 - val_accuracy: 0.4939\n",
            "Epoch 14/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1998 - accuracy: 0.5156\n",
            "Epoch 14: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 14: accuracy improved from 0.51212 to 0.51562, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 80s 815ms/step - loss: 1.1998 - accuracy: 0.5156 - val_loss: 1.8168 - val_accuracy: 0.3922\n",
            "Epoch 15/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2651 - accuracy: 0.5143\n",
            "Epoch 15: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.51562\n",
            "98/98 [==============================] - 78s 796ms/step - loss: 1.2651 - accuracy: 0.5143 - val_loss: 1.6519 - val_accuracy: 0.4503\n",
            "Epoch 16/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2670 - accuracy: 0.5182\n",
            "Epoch 16: val_accuracy did not improve from 0.52626\n",
            "\n",
            "Epoch 16: accuracy improved from 0.51562 to 0.51818, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 79s 810ms/step - loss: 1.2670 - accuracy: 0.5182 - val_loss: 1.4163 - val_accuracy: 0.4034\n",
            "Epoch 17/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1983 - accuracy: 0.5344\n",
            "Epoch 17: val_accuracy improved from 0.52626 to 0.59553, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 17: accuracy improved from 0.51818 to 0.53444, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 82s 833ms/step - loss: 1.1983 - accuracy: 0.5344 - val_loss: 1.0092 - val_accuracy: 0.5955\n",
            "Epoch 18/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0283 - accuracy: 0.5641\n",
            "Epoch 18: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 18: accuracy improved from 0.53444 to 0.56409, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 84s 857ms/step - loss: 1.0283 - accuracy: 0.5641 - val_loss: 1.1045 - val_accuracy: 0.5475\n",
            "Epoch 19/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2787 - accuracy: 0.5230\n",
            "Epoch 19: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.56409\n",
            "98/98 [==============================] - 80s 818ms/step - loss: 1.2787 - accuracy: 0.5230 - val_loss: 1.2522 - val_accuracy: 0.4682\n",
            "Epoch 20/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1810 - accuracy: 0.5367\n",
            "Epoch 20: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.56409\n",
            "98/98 [==============================] - 80s 814ms/step - loss: 1.1810 - accuracy: 0.5367 - val_loss: 1.1086 - val_accuracy: 0.5575\n",
            "Epoch 21/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.5526\n",
            "Epoch 21: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.56409\n",
            "98/98 [==============================] - 79s 804ms/step - loss: 1.1504 - accuracy: 0.5526 - val_loss: 1.1512 - val_accuracy: 0.5050\n",
            "Epoch 22/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2854 - accuracy: 0.5290\n",
            "Epoch 22: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.56409\n",
            "98/98 [==============================] - 78s 793ms/step - loss: 1.2854 - accuracy: 0.5290 - val_loss: 1.1671 - val_accuracy: 0.5709\n",
            "Epoch 23/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0474 - accuracy: 0.5820\n",
            "Epoch 23: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 23: accuracy improved from 0.56409 to 0.58195, saving model to /content/drive/MyDrive/defense/ResNet50/highest_train2.h5\n",
            "98/98 [==============================] - 79s 802ms/step - loss: 1.0474 - accuracy: 0.5820 - val_loss: 1.0012 - val_accuracy: 0.5821\n",
            "Epoch 24/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1016 - accuracy: 0.5670\n",
            "Epoch 24: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.58195\n",
            "98/98 [==============================] - 77s 786ms/step - loss: 1.1016 - accuracy: 0.5670 - val_loss: 1.5215 - val_accuracy: 0.5497\n",
            "Epoch 25/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.3081 - accuracy: 0.5258\n",
            "Epoch 25: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.58195\n",
            "98/98 [==============================] - 77s 788ms/step - loss: 1.3081 - accuracy: 0.5258 - val_loss: 1.1886 - val_accuracy: 0.5721\n",
            "Epoch 26/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.5807\n",
            "Epoch 26: val_accuracy did not improve from 0.59553\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.58195\n",
            "98/98 [==============================] - 76s 780ms/step - loss: 1.0983 - accuracy: 0.5807 - val_loss: 1.2578 - val_accuracy: 0.5385\n",
            "Epoch 27/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0726 - accuracy: 0.5778\n",
            "Epoch 27: val_accuracy improved from 0.59553 to 0.61788, saving model to /content/drive/MyDrive/defense/ResNet50/highest_val2.h5\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.58195\n",
            "98/98 [==============================] - 80s 812ms/step - loss: 1.0726 - accuracy: 0.5778 - val_loss: 0.9964 - val_accuracy: 0.6179\n",
            "Epoch 28/160\n",
            "48/98 [=============>................] - ETA: 34s - loss: 1.1393 - accuracy: 0.5586"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/drive/MyDrive/defense/ResNet50/highest_val2.h5\"\n",
        "filepath2 = \"/content/drive/MyDrive/defense/ResNet50/highest_train2.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "checkpoint2 = ModelCheckpoint(filepath2, monitor='accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1,checkpoint2]\n",
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    epochs=160,\n",
        "    validation_data=val_set,\n",
        "    steps_per_epoch=len(training_set),\n",
        "    validation_steps=len(val_set),\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "model.save_weights(\"/content/drive/MyDrive/defense/ResNet50/end2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "rt7PKjgCaaLP",
        "outputId": "7d16c039-0336-41b5-ca6a-2fd25590e79d"
      },
      "outputs": [],
      "source": [
        "\n",
        "#plot of accuracy and loss\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.title('Training and validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u6uTAxTaaOa",
        "outputId": "011192eb-8e47-44ec-bf2e-9cbec9800aeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2006: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss = 0.821776807308197\n",
            "Test Accuracy = 0.773809552192688\n"
          ]
        }
      ],
      "source": [
        "#evaluating the model (test acc)\n",
        "#batch size = 32\n",
        "model.load_weights('/content/drive/MyDrive/Onion Diseases/Accuracy /ResNet50/highest_val2.h5')\n",
        "preds = model.evaluate_generator(test_set)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "1HaCDpKca3Yd",
        "outputId": "ffa4b98e-dbbf-4983-e0fc-816affb2a94e"
      },
      "outputs": [],
      "source": [
        "#confusion matrix\n",
        "\n",
        "#you have to set test bath size=1 before running the cell\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "model.load_weights('/content/drive/MyDrive/Onion Diseases/Accuracy /ResNet50/highest_val2.h5')\n",
        "filenames=test_set.filenames\n",
        "nb_samples=len(test_set)\n",
        "y_prob=[]\n",
        "y_act=[]\n",
        "test_set.reset()\n",
        "for _ in range (nb_samples):\n",
        "    X_test,Y_test = test_set.next()\n",
        "    y_prob.append(model.predict(X_test))\n",
        "    y_act.append(Y_test)\n",
        "predicted_class=[list(training_set.class_indices.keys())[i.argmax()] for i in y_prob]\n",
        "actual_class=[list(training_set.class_indices.keys())[i.argmax()]for i in y_act]\n",
        "out_df=pd.DataFrame(np.vstack([predicted_class,actual_class]).T,columns=['predicted_class','actual_class'])\n",
        "confusion_matrix=pd.crosstab(out_df['actual_class'],out_df['predicted_class'],rownames=['Actual'],colnames=['Predicted'])\n",
        "import matplotlib.pyplot as plt\n",
        "sn.heatmap(confusion_matrix,cmap='flare', annot=True, fmt='d')\n",
        "plt.show()\n",
        "#plt.savefig('/content/drive/MyDrive/model weights/vgg16_AugGfb_split1_maxval_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfe3JvsHa3iw"
      },
      "outputs": [],
      "source": [
        "lst=[r.history['loss'],r.history['val_loss'],r.history['accuracy'],r.history['val_accuracy']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "_L24-mh_7XJ7",
        "outputId": "be032770-ae95-4df5-b7ce-c54e99b177f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.869423</td>\n",
              "      <td>1.804300</td>\n",
              "      <td>1.703288</td>\n",
              "      <td>1.484288</td>\n",
              "      <td>1.407032</td>\n",
              "      <td>1.582208</td>\n",
              "      <td>1.432651</td>\n",
              "      <td>1.267886</td>\n",
              "      <td>1.350396</td>\n",
              "      <td>1.179225</td>\n",
              "      <td>1.283551</td>\n",
              "      <td>1.164104</td>\n",
              "      <td>1.323075</td>\n",
              "      <td>1.163417</td>\n",
              "      <td>1.281835</td>\n",
              "      <td>1.125181</td>\n",
              "      <td>1.057142</td>\n",
              "      <td>1.175921</td>\n",
              "      <td>1.192630</td>\n",
              "      <td>1.204210</td>\n",
              "      <td>1.115507</td>\n",
              "      <td>1.066585</td>\n",
              "      <td>1.026756</td>\n",
              "      <td>1.154116</td>\n",
              "      <td>0.985939</td>\n",
              "      <td>1.152268</td>\n",
              "      <td>1.020498</td>\n",
              "      <td>1.057915</td>\n",
              "      <td>1.381507</td>\n",
              "      <td>0.894095</td>\n",
              "      <td>1.012724</td>\n",
              "      <td>0.951464</td>\n",
              "      <td>1.004424</td>\n",
              "      <td>0.940791</td>\n",
              "      <td>1.194896</td>\n",
              "      <td>1.087017</td>\n",
              "      <td>0.885508</td>\n",
              "      <td>0.902468</td>\n",
              "      <td>1.070229</td>\n",
              "      <td>0.949711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.710397</td>\n",
              "      <td>0.765244</td>\n",
              "      <td>0.716947</td>\n",
              "      <td>0.574929</td>\n",
              "      <td>0.594573</td>\n",
              "      <td>0.591380</td>\n",
              "      <td>0.866335</td>\n",
              "      <td>0.757995</td>\n",
              "      <td>0.727700</td>\n",
              "      <td>0.594640</td>\n",
              "      <td>0.619796</td>\n",
              "      <td>0.676708</td>\n",
              "      <td>0.719936</td>\n",
              "      <td>0.729068</td>\n",
              "      <td>0.669281</td>\n",
              "      <td>0.638376</td>\n",
              "      <td>0.727684</td>\n",
              "      <td>0.606521</td>\n",
              "      <td>0.638911</td>\n",
              "      <td>0.843841</td>\n",
              "      <td>0.944651</td>\n",
              "      <td>0.573405</td>\n",
              "      <td>0.917740</td>\n",
              "      <td>0.905083</td>\n",
              "      <td>0.660692</td>\n",
              "      <td>0.574445</td>\n",
              "      <td>0.644448</td>\n",
              "      <td>0.634047</td>\n",
              "      <td>0.640869</td>\n",
              "      <td>0.535481</td>\n",
              "      <td>0.846208</td>\n",
              "      <td>0.628388</td>\n",
              "      <td>0.661492</td>\n",
              "      <td>0.796838</td>\n",
              "      <td>0.606268</td>\n",
              "      <td>0.665078</td>\n",
              "      <td>0.643782</td>\n",
              "      <td>0.839710</td>\n",
              "      <td>0.846258</td>\n",
              "      <td>0.668104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.261816</td>\n",
              "      <td>1.391285</td>\n",
              "      <td>2.233489</td>\n",
              "      <td>1.645025</td>\n",
              "      <td>1.396253</td>\n",
              "      <td>1.824860</td>\n",
              "      <td>1.475054</td>\n",
              "      <td>1.118352</td>\n",
              "      <td>1.187162</td>\n",
              "      <td>1.662094</td>\n",
              "      <td>1.081624</td>\n",
              "      <td>1.098304</td>\n",
              "      <td>1.000320</td>\n",
              "      <td>1.708298</td>\n",
              "      <td>1.884966</td>\n",
              "      <td>0.941100</td>\n",
              "      <td>1.033892</td>\n",
              "      <td>1.328767</td>\n",
              "      <td>1.313453</td>\n",
              "      <td>1.240766</td>\n",
              "      <td>1.040286</td>\n",
              "      <td>0.846798</td>\n",
              "      <td>1.726385</td>\n",
              "      <td>0.839719</td>\n",
              "      <td>0.912435</td>\n",
              "      <td>1.098501</td>\n",
              "      <td>1.044576</td>\n",
              "      <td>1.032382</td>\n",
              "      <td>0.947645</td>\n",
              "      <td>0.904537</td>\n",
              "      <td>1.133282</td>\n",
              "      <td>0.959801</td>\n",
              "      <td>1.089944</td>\n",
              "      <td>1.424622</td>\n",
              "      <td>1.428304</td>\n",
              "      <td>1.254242</td>\n",
              "      <td>0.995542</td>\n",
              "      <td>1.261873</td>\n",
              "      <td>0.928183</td>\n",
              "      <td>2.246228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.757306</td>\n",
              "      <td>1.081612</td>\n",
              "      <td>0.638820</td>\n",
              "      <td>0.832434</td>\n",
              "      <td>0.688142</td>\n",
              "      <td>0.755485</td>\n",
              "      <td>0.757232</td>\n",
              "      <td>0.819963</td>\n",
              "      <td>0.640568</td>\n",
              "      <td>0.944299</td>\n",
              "      <td>0.769298</td>\n",
              "      <td>0.776725</td>\n",
              "      <td>0.982369</td>\n",
              "      <td>0.853733</td>\n",
              "      <td>0.762245</td>\n",
              "      <td>0.901339</td>\n",
              "      <td>0.787865</td>\n",
              "      <td>0.669449</td>\n",
              "      <td>1.283528</td>\n",
              "      <td>0.917625</td>\n",
              "      <td>0.704668</td>\n",
              "      <td>1.018072</td>\n",
              "      <td>1.098369</td>\n",
              "      <td>1.638518</td>\n",
              "      <td>0.978841</td>\n",
              "      <td>1.096704</td>\n",
              "      <td>0.899523</td>\n",
              "      <td>0.949629</td>\n",
              "      <td>0.785845</td>\n",
              "      <td>0.841954</td>\n",
              "      <td>0.851926</td>\n",
              "      <td>0.793916</td>\n",
              "      <td>0.999514</td>\n",
              "      <td>0.987346</td>\n",
              "      <td>1.058963</td>\n",
              "      <td>0.812826</td>\n",
              "      <td>0.718272</td>\n",
              "      <td>0.797232</td>\n",
              "      <td>0.756547</td>\n",
              "      <td>1.154406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.297149</td>\n",
              "      <td>0.357953</td>\n",
              "      <td>0.378908</td>\n",
              "      <td>0.404328</td>\n",
              "      <td>0.422879</td>\n",
              "      <td>0.417039</td>\n",
              "      <td>0.452078</td>\n",
              "      <td>0.488492</td>\n",
              "      <td>0.465819</td>\n",
              "      <td>0.520783</td>\n",
              "      <td>0.500515</td>\n",
              "      <td>0.530058</td>\n",
              "      <td>0.495019</td>\n",
              "      <td>0.532807</td>\n",
              "      <td>0.520440</td>\n",
              "      <td>0.536242</td>\n",
              "      <td>0.571968</td>\n",
              "      <td>0.555823</td>\n",
              "      <td>0.545517</td>\n",
              "      <td>0.552387</td>\n",
              "      <td>0.568190</td>\n",
              "      <td>0.581931</td>\n",
              "      <td>0.591893</td>\n",
              "      <td>0.578152</td>\n",
              "      <td>0.602199</td>\n",
              "      <td>0.560632</td>\n",
              "      <td>0.598420</td>\n",
              "      <td>0.588801</td>\n",
              "      <td>0.558227</td>\n",
              "      <td>0.646170</td>\n",
              "      <td>0.620405</td>\n",
              "      <td>0.632085</td>\n",
              "      <td>0.612504</td>\n",
              "      <td>0.630024</td>\n",
              "      <td>0.567503</td>\n",
              "      <td>0.610443</td>\n",
              "      <td>0.648574</td>\n",
              "      <td>0.642734</td>\n",
              "      <td>0.623497</td>\n",
              "      <td>0.635520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.742013</td>\n",
              "      <td>0.723806</td>\n",
              "      <td>0.736860</td>\n",
              "      <td>0.775335</td>\n",
              "      <td>0.771900</td>\n",
              "      <td>0.784610</td>\n",
              "      <td>0.707661</td>\n",
              "      <td>0.729990</td>\n",
              "      <td>0.725524</td>\n",
              "      <td>0.774304</td>\n",
              "      <td>0.764686</td>\n",
              "      <td>0.745448</td>\n",
              "      <td>0.725867</td>\n",
              "      <td>0.726554</td>\n",
              "      <td>0.746479</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.733081</td>\n",
              "      <td>0.767090</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.704569</td>\n",
              "      <td>0.701134</td>\n",
              "      <td>0.782892</td>\n",
              "      <td>0.692202</td>\n",
              "      <td>0.694950</td>\n",
              "      <td>0.751632</td>\n",
              "      <td>0.781518</td>\n",
              "      <td>0.760907</td>\n",
              "      <td>0.774991</td>\n",
              "      <td>0.761250</td>\n",
              "      <td>0.802817</td>\n",
              "      <td>0.715562</td>\n",
              "      <td>0.773274</td>\n",
              "      <td>0.749227</td>\n",
              "      <td>0.726211</td>\n",
              "      <td>0.790794</td>\n",
              "      <td>0.743731</td>\n",
              "      <td>0.765373</td>\n",
              "      <td>0.723806</td>\n",
              "      <td>0.721402</td>\n",
              "      <td>0.761594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.444043</td>\n",
              "      <td>0.361011</td>\n",
              "      <td>0.309266</td>\n",
              "      <td>0.347774</td>\n",
              "      <td>0.398315</td>\n",
              "      <td>0.318893</td>\n",
              "      <td>0.416366</td>\n",
              "      <td>0.500602</td>\n",
              "      <td>0.484958</td>\n",
              "      <td>0.388688</td>\n",
              "      <td>0.567990</td>\n",
              "      <td>0.537906</td>\n",
              "      <td>0.563177</td>\n",
              "      <td>0.474128</td>\n",
              "      <td>0.353791</td>\n",
              "      <td>0.596871</td>\n",
              "      <td>0.574007</td>\n",
              "      <td>0.471721</td>\n",
              "      <td>0.512635</td>\n",
              "      <td>0.484958</td>\n",
              "      <td>0.575211</td>\n",
              "      <td>0.671480</td>\n",
              "      <td>0.530686</td>\n",
              "      <td>0.652226</td>\n",
              "      <td>0.613718</td>\n",
              "      <td>0.586041</td>\n",
              "      <td>0.561974</td>\n",
              "      <td>0.598075</td>\n",
              "      <td>0.631769</td>\n",
              "      <td>0.623345</td>\n",
              "      <td>0.545126</td>\n",
              "      <td>0.611312</td>\n",
              "      <td>0.598075</td>\n",
              "      <td>0.481348</td>\n",
              "      <td>0.515042</td>\n",
              "      <td>0.543923</td>\n",
              "      <td>0.641396</td>\n",
              "      <td>0.628159</td>\n",
              "      <td>0.652226</td>\n",
              "      <td>0.466907</td>\n",
              "      <td>...</td>\n",
              "      <td>0.725632</td>\n",
              "      <td>0.663057</td>\n",
              "      <td>0.777377</td>\n",
              "      <td>0.720818</td>\n",
              "      <td>0.767750</td>\n",
              "      <td>0.726835</td>\n",
              "      <td>0.731649</td>\n",
              "      <td>0.716005</td>\n",
              "      <td>0.774970</td>\n",
              "      <td>0.682310</td>\n",
              "      <td>0.736462</td>\n",
              "      <td>0.718412</td>\n",
              "      <td>0.645006</td>\n",
              "      <td>0.712395</td>\n",
              "      <td>0.749699</td>\n",
              "      <td>0.678700</td>\n",
              "      <td>0.736462</td>\n",
              "      <td>0.768953</td>\n",
              "      <td>0.572804</td>\n",
              "      <td>0.696751</td>\n",
              "      <td>0.767750</td>\n",
              "      <td>0.654633</td>\n",
              "      <td>0.660650</td>\n",
              "      <td>0.558363</td>\n",
              "      <td>0.689531</td>\n",
              "      <td>0.634176</td>\n",
              "      <td>0.714801</td>\n",
              "      <td>0.695548</td>\n",
              "      <td>0.743682</td>\n",
              "      <td>0.706378</td>\n",
              "      <td>0.712395</td>\n",
              "      <td>0.746089</td>\n",
              "      <td>0.694344</td>\n",
              "      <td>0.682310</td>\n",
              "      <td>0.649819</td>\n",
              "      <td>0.705175</td>\n",
              "      <td>0.776173</td>\n",
              "      <td>0.736462</td>\n",
              "      <td>0.749699</td>\n",
              "      <td>0.691937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 160 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       157       158       159\n",
              "0  2.869423  1.804300  1.703288  ...  0.839710  0.846258  0.668104\n",
              "1  1.261816  1.391285  2.233489  ...  0.797232  0.756547  1.154406\n",
              "2  0.297149  0.357953  0.378908  ...  0.723806  0.721402  0.761594\n",
              "3  0.444043  0.361011  0.309266  ...  0.736462  0.749699  0.691937\n",
              "\n",
              "[4 rows x 160 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(lst)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYsba_M_7XNO"
      },
      "outputs": [],
      "source": [
        "df.to_csv('RestNet.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
