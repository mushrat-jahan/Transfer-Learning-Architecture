{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMjjPw3IzG17",
        "outputId": "2713e590-39fa-4b0e-b9f2-1097f3ecaf2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul  2 11:04:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9dMnclHzeC6",
        "outputId": "28e5297f-7f90-41b0-8088-ced83c205f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,124,740\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Loading deep learning algorithm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import keras\n",
        "#import keras.backend as K\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "IMAGE_SIZE = [224,224]\n",
        "CLASS=4\n",
        "inception = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "#model = VGG16(weights='imagenet', include_top=False)\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False\n",
        "#folders = glob('C:\\rafid\\guava disease research\\k_guava\\train_image/*')\n",
        "x = Flatten()(inception.output)\n",
        "prediction = Dense(CLASS, activation='softmax')(x)\n",
        "model = Model(inputs=inception.input, outputs=prediction)\n",
        "adam = keras.optimizers.Adam(lr = 0.001)\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer = adam,\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2kq03EtsN49",
        "outputId": "b5310f44-4ddb-431d-d833-30b9d8270398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfPbiGybzeNK",
        "outputId": "a6bc88b2-09a8-480c-8da7-0da1d2c07367"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "val_set = val_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/val',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/defense/Split-dataset/test',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'categorical')\n",
        "print(\"\\n\\n\")\n",
        "model.optimizer.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqo2UcB3zeQT",
        "outputId": "5ea490a4-5e5b-4396-8fa4-ac557b1efd93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-d1eae2c92275>:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  r = model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1830 - accuracy: 0.5580\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70838, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.55804, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 777s 8s/step - loss: 1.1830 - accuracy: 0.5580 - val_loss: 0.7514 - val_accuracy: 0.7084\n",
            "Epoch 2/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.7430\n",
            "Epoch 2: val_accuracy improved from 0.70838 to 0.77318, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.55804 to 0.74298, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 77s 782ms/step - loss: 0.6837 - accuracy: 0.7430 - val_loss: 0.6051 - val_accuracy: 0.7732\n",
            "Epoch 3/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.7886\n",
            "Epoch 3: val_accuracy did not improve from 0.77318\n",
            "\n",
            "Epoch 3: accuracy improved from 0.74298 to 0.78858, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 78s 796ms/step - loss: 0.5681 - accuracy: 0.7886 - val_loss: 0.6467 - val_accuracy: 0.7642\n",
            "Epoch 4/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.8463\n",
            "Epoch 4: val_accuracy improved from 0.77318 to 0.78771, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.78858 to 0.84630, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 77s 788ms/step - loss: 0.4379 - accuracy: 0.8463 - val_loss: 0.5316 - val_accuracy: 0.7877\n",
            "Epoch 5/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8683\n",
            "Epoch 5: val_accuracy improved from 0.78771 to 0.80559, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.84630 to 0.86830, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 76s 780ms/step - loss: 0.3781 - accuracy: 0.8683 - val_loss: 0.5009 - val_accuracy: 0.8056\n",
            "Epoch 6/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8626\n",
            "Epoch 6: val_accuracy improved from 0.80559 to 0.84134, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.86830\n",
            "98/98 [==============================] - 76s 774ms/step - loss: 0.3768 - accuracy: 0.8626 - val_loss: 0.4267 - val_accuracy: 0.8413\n",
            "Epoch 7/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8865\n",
            "Epoch 7: val_accuracy did not improve from 0.84134\n",
            "\n",
            "Epoch 7: accuracy improved from 0.86830 to 0.88648, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 768ms/step - loss: 0.3198 - accuracy: 0.8865 - val_loss: 0.4535 - val_accuracy: 0.8246\n",
            "Epoch 8/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8964\n",
            "Epoch 8: val_accuracy improved from 0.84134 to 0.84804, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 8: accuracy improved from 0.88648 to 0.89636, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 76s 773ms/step - loss: 0.3047 - accuracy: 0.8964 - val_loss: 0.4214 - val_accuracy: 0.8480\n",
            "Epoch 9/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.9187\n",
            "Epoch 9: val_accuracy improved from 0.84804 to 0.85698, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 9: accuracy improved from 0.89636 to 0.91869, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 768ms/step - loss: 0.2593 - accuracy: 0.9187 - val_loss: 0.3924 - val_accuracy: 0.8570\n",
            "Epoch 10/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.9161\n",
            "Epoch 10: val_accuracy did not improve from 0.85698\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.91869\n",
            "98/98 [==============================] - 76s 774ms/step - loss: 0.2481 - accuracy: 0.9161 - val_loss: 0.4145 - val_accuracy: 0.8525\n",
            "Epoch 11/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9043\n",
            "Epoch 11: val_accuracy did not improve from 0.85698\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.91869\n",
            "98/98 [==============================] - 74s 750ms/step - loss: 0.2705 - accuracy: 0.9043 - val_loss: 0.4506 - val_accuracy: 0.8380\n",
            "Epoch 12/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9196\n",
            "Epoch 12: val_accuracy improved from 0.85698 to 0.86034, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 12: accuracy improved from 0.91869 to 0.91964, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 79s 804ms/step - loss: 0.2260 - accuracy: 0.9196 - val_loss: 0.3905 - val_accuracy: 0.8603\n",
            "Epoch 13/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.9305\n",
            "Epoch 13: val_accuracy did not improve from 0.86034\n",
            "\n",
            "Epoch 13: accuracy improved from 0.91964 to 0.93048, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 759ms/step - loss: 0.2110 - accuracy: 0.9305 - val_loss: 0.4152 - val_accuracy: 0.8514\n",
            "Epoch 14/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9139\n",
            "Epoch 14: val_accuracy did not improve from 0.86034\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.93048\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.2383 - accuracy: 0.9139 - val_loss: 0.4401 - val_accuracy: 0.8402\n",
            "Epoch 15/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9158\n",
            "Epoch 15: val_accuracy did not improve from 0.86034\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.93048\n",
            "98/98 [==============================] - 75s 767ms/step - loss: 0.2304 - accuracy: 0.9158 - val_loss: 0.4842 - val_accuracy: 0.8480\n",
            "Epoch 16/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9276\n",
            "Epoch 16: val_accuracy improved from 0.86034 to 0.87039, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.93048\n",
            "98/98 [==============================] - 74s 759ms/step - loss: 0.2066 - accuracy: 0.9276 - val_loss: 0.3586 - val_accuracy: 0.8704\n",
            "Epoch 17/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9509\n",
            "Epoch 17: val_accuracy did not improve from 0.87039\n",
            "\n",
            "Epoch 17: accuracy improved from 0.93048 to 0.95089, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 769ms/step - loss: 0.1540 - accuracy: 0.9509 - val_loss: 0.3771 - val_accuracy: 0.8693\n",
            "Epoch 18/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9346\n",
            "Epoch 18: val_accuracy did not improve from 0.87039\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.95089\n",
            "98/98 [==============================] - 75s 768ms/step - loss: 0.1819 - accuracy: 0.9346 - val_loss: 0.4620 - val_accuracy: 0.8413\n",
            "Epoch 19/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9464\n",
            "Epoch 19: val_accuracy improved from 0.87039 to 0.87151, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.95089\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.1623 - accuracy: 0.9464 - val_loss: 0.3698 - val_accuracy: 0.8715\n",
            "Epoch 20/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9515\n",
            "Epoch 20: val_accuracy did not improve from 0.87151\n",
            "\n",
            "Epoch 20: accuracy improved from 0.95089 to 0.95153, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 757ms/step - loss: 0.1518 - accuracy: 0.9515 - val_loss: 0.3742 - val_accuracy: 0.8715\n",
            "Epoch 21/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9432\n",
            "Epoch 21: val_accuracy did not improve from 0.87151\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.95153\n",
            "98/98 [==============================] - 74s 759ms/step - loss: 0.1696 - accuracy: 0.9432 - val_loss: 0.3892 - val_accuracy: 0.8659\n",
            "Epoch 22/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9534\n",
            "Epoch 22: val_accuracy did not improve from 0.87151\n",
            "\n",
            "Epoch 22: accuracy improved from 0.95153 to 0.95344, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 757ms/step - loss: 0.1439 - accuracy: 0.9534 - val_loss: 0.3882 - val_accuracy: 0.8648\n",
            "Epoch 23/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 0.9448\n",
            "Epoch 23: val_accuracy did not improve from 0.87151\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.95344\n",
            "98/98 [==============================] - 74s 758ms/step - loss: 0.1595 - accuracy: 0.9448 - val_loss: 0.4714 - val_accuracy: 0.8458\n",
            "Epoch 24/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9538\n",
            "Epoch 24: val_accuracy did not improve from 0.87151\n",
            "\n",
            "Epoch 24: accuracy improved from 0.95344 to 0.95376, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 762ms/step - loss: 0.1391 - accuracy: 0.9538 - val_loss: 0.4921 - val_accuracy: 0.8402\n",
            "Epoch 25/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9627\n",
            "Epoch 25: val_accuracy improved from 0.87151 to 0.87486, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 25: accuracy improved from 0.95376 to 0.96269, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 76s 771ms/step - loss: 0.1192 - accuracy: 0.9627 - val_loss: 0.4003 - val_accuracy: 0.8749\n",
            "Epoch 26/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9410\n",
            "Epoch 26: val_accuracy did not improve from 0.87486\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.1699 - accuracy: 0.9410 - val_loss: 0.4421 - val_accuracy: 0.8615\n",
            "Epoch 27/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9570\n",
            "Epoch 27: val_accuracy did not improve from 0.87486\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.1241 - accuracy: 0.9570 - val_loss: 0.4096 - val_accuracy: 0.8682\n",
            "Epoch 28/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9621\n",
            "Epoch 28: val_accuracy did not improve from 0.87486\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.1131 - accuracy: 0.9621 - val_loss: 0.4436 - val_accuracy: 0.8693\n",
            "Epoch 29/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9531\n",
            "Epoch 29: val_accuracy did not improve from 0.87486\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.1328 - accuracy: 0.9531 - val_loss: 0.4249 - val_accuracy: 0.8581\n",
            "Epoch 30/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9595\n",
            "Epoch 30: val_accuracy did not improve from 0.87486\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 75s 767ms/step - loss: 0.1196 - accuracy: 0.9595 - val_loss: 0.5430 - val_accuracy: 0.8313\n",
            "Epoch 31/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9617\n",
            "Epoch 31: val_accuracy improved from 0.87486 to 0.87933, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.96269\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.1179 - accuracy: 0.9617 - val_loss: 0.4026 - val_accuracy: 0.8793\n",
            "Epoch 32/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9732\n",
            "Epoch 32: val_accuracy improved from 0.87933 to 0.88603, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 32: accuracy improved from 0.96269 to 0.97321, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 77s 785ms/step - loss: 0.0917 - accuracy: 0.9732 - val_loss: 0.3861 - val_accuracy: 0.8860\n",
            "Epoch 33/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9455\n",
            "Epoch 33: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.1533 - accuracy: 0.9455 - val_loss: 0.5933 - val_accuracy: 0.8335\n",
            "Epoch 34/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9614\n",
            "Epoch 34: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.1152 - accuracy: 0.9614 - val_loss: 0.4532 - val_accuracy: 0.8570\n",
            "Epoch 35/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9566\n",
            "Epoch 35: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 750ms/step - loss: 0.1209 - accuracy: 0.9566 - val_loss: 0.5675 - val_accuracy: 0.8447\n",
            "Epoch 36/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9598\n",
            "Epoch 36: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 74s 753ms/step - loss: 0.1208 - accuracy: 0.9598 - val_loss: 0.5230 - val_accuracy: 0.8369\n",
            "Epoch 37/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9436\n",
            "Epoch 37: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.1571 - accuracy: 0.9436 - val_loss: 0.4330 - val_accuracy: 0.8860\n",
            "Epoch 38/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9691\n",
            "Epoch 38: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0925 - accuracy: 0.9691 - val_loss: 0.4722 - val_accuracy: 0.8749\n",
            "Epoch 39/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9646\n",
            "Epoch 39: val_accuracy did not improve from 0.88603\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 748ms/step - loss: 0.1073 - accuracy: 0.9646 - val_loss: 0.4384 - val_accuracy: 0.8737\n",
            "Epoch 40/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9636\n",
            "Epoch 40: val_accuracy improved from 0.88603 to 0.88715, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 76s 773ms/step - loss: 0.0954 - accuracy: 0.9636 - val_loss: 0.4128 - val_accuracy: 0.8872\n",
            "Epoch 41/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9694\n",
            "Epoch 41: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 74s 748ms/step - loss: 0.0879 - accuracy: 0.9694 - val_loss: 0.4103 - val_accuracy: 0.8804\n",
            "Epoch 42/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9684\n",
            "Epoch 42: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0929 - accuracy: 0.9684 - val_loss: 0.4381 - val_accuracy: 0.8771\n",
            "Epoch 43/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9656\n",
            "Epoch 43: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0940 - accuracy: 0.9656 - val_loss: 0.4237 - val_accuracy: 0.8771\n",
            "Epoch 44/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9688\n",
            "Epoch 44: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 75s 761ms/step - loss: 0.0919 - accuracy: 0.9688 - val_loss: 0.4706 - val_accuracy: 0.8704\n",
            "Epoch 45/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9436\n",
            "Epoch 45: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.1644 - accuracy: 0.9436 - val_loss: 0.4227 - val_accuracy: 0.8860\n",
            "Epoch 46/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9726\n",
            "Epoch 46: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 745ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.4596 - val_accuracy: 0.8637\n",
            "Epoch 47/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9662\n",
            "Epoch 47: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0960 - accuracy: 0.9662 - val_loss: 0.4769 - val_accuracy: 0.8670\n",
            "Epoch 48/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9703\n",
            "Epoch 48: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.97321\n",
            "98/98 [==============================] - 73s 742ms/step - loss: 0.0884 - accuracy: 0.9703 - val_loss: 0.4488 - val_accuracy: 0.8670\n",
            "Epoch 49/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9758\n",
            "Epoch 49: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 49: accuracy improved from 0.97321 to 0.97577, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0712 - accuracy: 0.9758 - val_loss: 0.4768 - val_accuracy: 0.8659\n",
            "Epoch 50/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9745\n",
            "Epoch 50: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 748ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.5325 - val_accuracy: 0.8693\n",
            "Epoch 51/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9691\n",
            "Epoch 51: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 743ms/step - loss: 0.0908 - accuracy: 0.9691 - val_loss: 0.4404 - val_accuracy: 0.8737\n",
            "Epoch 52/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9716\n",
            "Epoch 52: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0745 - accuracy: 0.9716 - val_loss: 0.4333 - val_accuracy: 0.8838\n",
            "Epoch 53/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9668\n",
            "Epoch 53: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 750ms/step - loss: 0.0931 - accuracy: 0.9668 - val_loss: 0.4635 - val_accuracy: 0.8793\n",
            "Epoch 54/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9732\n",
            "Epoch 54: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.0843 - accuracy: 0.9732 - val_loss: 0.4526 - val_accuracy: 0.8771\n",
            "Epoch 55/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9719\n",
            "Epoch 55: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 75s 764ms/step - loss: 0.0873 - accuracy: 0.9719 - val_loss: 0.4449 - val_accuracy: 0.8782\n",
            "Epoch 56/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9707\n",
            "Epoch 56: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 743ms/step - loss: 0.0939 - accuracy: 0.9707 - val_loss: 0.4670 - val_accuracy: 0.8726\n",
            "Epoch 57/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9729\n",
            "Epoch 57: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 73s 742ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.5004 - val_accuracy: 0.8592\n",
            "Epoch 58/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9751\n",
            "Epoch 58: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.97577\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0789 - accuracy: 0.9751 - val_loss: 0.4986 - val_accuracy: 0.8626\n",
            "Epoch 59/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9770\n",
            "Epoch 59: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 59: accuracy improved from 0.97577 to 0.97704, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 755ms/step - loss: 0.0675 - accuracy: 0.9770 - val_loss: 0.5486 - val_accuracy: 0.8693\n",
            "Epoch 60/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9777\n",
            "Epoch 60: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 60: accuracy improved from 0.97704 to 0.97768, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 766ms/step - loss: 0.0662 - accuracy: 0.9777 - val_loss: 0.5306 - val_accuracy: 0.8670\n",
            "Epoch 61/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9783\n",
            "Epoch 61: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 61: accuracy improved from 0.97768 to 0.97832, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 76s 775ms/step - loss: 0.0659 - accuracy: 0.9783 - val_loss: 0.6930 - val_accuracy: 0.8358\n",
            "Epoch 62/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9662\n",
            "Epoch 62: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.97832\n",
            "98/98 [==============================] - 73s 743ms/step - loss: 0.1055 - accuracy: 0.9662 - val_loss: 0.4779 - val_accuracy: 0.8715\n",
            "Epoch 63/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9735\n",
            "Epoch 63: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.97832\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.0805 - accuracy: 0.9735 - val_loss: 0.5396 - val_accuracy: 0.8693\n",
            "Epoch 64/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9665\n",
            "Epoch 64: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.97832\n",
            "98/98 [==============================] - 74s 755ms/step - loss: 0.0991 - accuracy: 0.9665 - val_loss: 0.5245 - val_accuracy: 0.8737\n",
            "Epoch 65/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9694\n",
            "Epoch 65: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.97832\n",
            "98/98 [==============================] - 74s 749ms/step - loss: 0.0837 - accuracy: 0.9694 - val_loss: 0.6573 - val_accuracy: 0.8503\n",
            "Epoch 66/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9745\n",
            "Epoch 66: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.97832\n",
            "98/98 [==============================] - 75s 762ms/step - loss: 0.0789 - accuracy: 0.9745 - val_loss: 0.5327 - val_accuracy: 0.8603\n",
            "Epoch 67/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9793\n",
            "Epoch 67: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 67: accuracy improved from 0.97832 to 0.97927, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0618 - accuracy: 0.9793 - val_loss: 0.5453 - val_accuracy: 0.8659\n",
            "Epoch 68/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9726\n",
            "Epoch 68: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.97927\n",
            "98/98 [==============================] - 73s 745ms/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 0.4927 - val_accuracy: 0.8726\n",
            "Epoch 69/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9592\n",
            "Epoch 69: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.97927\n",
            "98/98 [==============================] - 73s 742ms/step - loss: 0.1203 - accuracy: 0.9592 - val_loss: 0.5948 - val_accuracy: 0.8514\n",
            "Epoch 70/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9719\n",
            "Epoch 70: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.97927\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0805 - accuracy: 0.9719 - val_loss: 0.5696 - val_accuracy: 0.8637\n",
            "Epoch 71/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9751\n",
            "Epoch 71: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.97927\n",
            "98/98 [==============================] - 73s 743ms/step - loss: 0.0724 - accuracy: 0.9751 - val_loss: 0.4699 - val_accuracy: 0.8816\n",
            "Epoch 72/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9828\n",
            "Epoch 72: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 72: accuracy improved from 0.97927 to 0.98278, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 770ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 0.5145 - val_accuracy: 0.8771\n",
            "Epoch 73/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9847\n",
            "Epoch 73: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 73: accuracy improved from 0.98278 to 0.98469, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.4854 - val_accuracy: 0.8749\n",
            "Epoch 74/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9761\n",
            "Epoch 74: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 75s 765ms/step - loss: 0.0633 - accuracy: 0.9761 - val_loss: 0.4802 - val_accuracy: 0.8827\n",
            "Epoch 75/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9761\n",
            "Epoch 75: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 73s 741ms/step - loss: 0.0741 - accuracy: 0.9761 - val_loss: 0.8988 - val_accuracy: 0.8291\n",
            "Epoch 76/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9723\n",
            "Epoch 76: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 73s 740ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 0.6192 - val_accuracy: 0.8536\n",
            "Epoch 77/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9774\n",
            "Epoch 77: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 73s 745ms/step - loss: 0.0739 - accuracy: 0.9774 - val_loss: 0.5174 - val_accuracy: 0.8704\n",
            "Epoch 78/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9805\n",
            "Epoch 78: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 75s 766ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.6014 - val_accuracy: 0.8559\n",
            "Epoch 79/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9716\n",
            "Epoch 79: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0870 - accuracy: 0.9716 - val_loss: 0.6110 - val_accuracy: 0.8536\n",
            "Epoch 80/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9703\n",
            "Epoch 80: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0871 - accuracy: 0.9703 - val_loss: 0.6125 - val_accuracy: 0.8715\n",
            "Epoch 81/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9729\n",
            "Epoch 81: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.98469\n",
            "98/98 [==============================] - 74s 759ms/step - loss: 0.0774 - accuracy: 0.9729 - val_loss: 0.5189 - val_accuracy: 0.8693\n",
            "Epoch 82/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9869\n",
            "Epoch 82: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 82: accuracy improved from 0.98469 to 0.98693, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 767ms/step - loss: 0.0397 - accuracy: 0.9869 - val_loss: 0.4958 - val_accuracy: 0.8749\n",
            "Epoch 83/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9688\n",
            "Epoch 83: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 76s 774ms/step - loss: 0.0835 - accuracy: 0.9688 - val_loss: 0.5055 - val_accuracy: 0.8771\n",
            "Epoch 84/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9550\n",
            "Epoch 84: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.1341 - accuracy: 0.9550 - val_loss: 0.6329 - val_accuracy: 0.8659\n",
            "Epoch 85/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9742\n",
            "Epoch 85: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0815 - accuracy: 0.9742 - val_loss: 0.6417 - val_accuracy: 0.8648\n",
            "Epoch 86/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9688\n",
            "Epoch 86: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.0875 - accuracy: 0.9688 - val_loss: 0.5451 - val_accuracy: 0.8793\n",
            "Epoch 87/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9742\n",
            "Epoch 87: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.0726 - accuracy: 0.9742 - val_loss: 0.5422 - val_accuracy: 0.8827\n",
            "Epoch 88/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9812\n",
            "Epoch 88: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 763ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.5714 - val_accuracy: 0.8749\n",
            "Epoch 89/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9809\n",
            "Epoch 89: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 762ms/step - loss: 0.0666 - accuracy: 0.9809 - val_loss: 0.5561 - val_accuracy: 0.8670\n",
            "Epoch 90/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9825\n",
            "Epoch 90: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.7873 - val_accuracy: 0.8458\n",
            "Epoch 91/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9777\n",
            "Epoch 91: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 750ms/step - loss: 0.0658 - accuracy: 0.9777 - val_loss: 0.5562 - val_accuracy: 0.8704\n",
            "Epoch 92/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9860\n",
            "Epoch 92: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.5524 - val_accuracy: 0.8715\n",
            "Epoch 93/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9841\n",
            "Epoch 93: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 755ms/step - loss: 0.0518 - accuracy: 0.9841 - val_loss: 0.5366 - val_accuracy: 0.8726\n",
            "Epoch 94/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9742\n",
            "Epoch 94: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.5912 - val_accuracy: 0.8704\n",
            "Epoch 95/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9841\n",
            "Epoch 95: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 746ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.5965 - val_accuracy: 0.8626\n",
            "Epoch 96/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9688\n",
            "Epoch 96: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0889 - accuracy: 0.9688 - val_loss: 0.5298 - val_accuracy: 0.8749\n",
            "Epoch 97/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9812\n",
            "Epoch 97: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 758ms/step - loss: 0.0618 - accuracy: 0.9812 - val_loss: 0.5708 - val_accuracy: 0.8816\n",
            "Epoch 98/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9786\n",
            "Epoch 98: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 761ms/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.6808 - val_accuracy: 0.8615\n",
            "Epoch 99/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9707\n",
            "Epoch 99: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 743ms/step - loss: 0.0764 - accuracy: 0.9707 - val_loss: 0.6987 - val_accuracy: 0.8514\n",
            "Epoch 100/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9850\n",
            "Epoch 100: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 745ms/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.5900 - val_accuracy: 0.8827\n",
            "Epoch 101/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9828\n",
            "Epoch 101: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 101: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 771ms/step - loss: 0.0557 - accuracy: 0.9828 - val_loss: 0.6116 - val_accuracy: 0.8648\n",
            "Epoch 102/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9850\n",
            "Epoch 102: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 102: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 0.6284 - val_accuracy: 0.8581\n",
            "Epoch 103/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9818\n",
            "Epoch 103: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 103: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 745ms/step - loss: 0.0539 - accuracy: 0.9818 - val_loss: 0.5719 - val_accuracy: 0.8760\n",
            "Epoch 104/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9777\n",
            "Epoch 104: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 104: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 763ms/step - loss: 0.0656 - accuracy: 0.9777 - val_loss: 0.5748 - val_accuracy: 0.8793\n",
            "Epoch 105/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9796\n",
            "Epoch 105: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 105: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.0550 - accuracy: 0.9796 - val_loss: 0.6446 - val_accuracy: 0.8592\n",
            "Epoch 106/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9805\n",
            "Epoch 106: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 106: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 762ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 0.5582 - val_accuracy: 0.8693\n",
            "Epoch 107/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9834\n",
            "Epoch 107: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 107: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.0499 - accuracy: 0.9834 - val_loss: 0.5569 - val_accuracy: 0.8793\n",
            "Epoch 108/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9841\n",
            "Epoch 108: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 108: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 762ms/step - loss: 0.0434 - accuracy: 0.9841 - val_loss: 0.5802 - val_accuracy: 0.8782\n",
            "Epoch 109/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9783\n",
            "Epoch 109: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 109: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 758ms/step - loss: 0.0641 - accuracy: 0.9783 - val_loss: 0.9105 - val_accuracy: 0.8369\n",
            "Epoch 110/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9841\n",
            "Epoch 110: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 110: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 753ms/step - loss: 0.0581 - accuracy: 0.9841 - val_loss: 0.6563 - val_accuracy: 0.8693\n",
            "Epoch 111/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9793\n",
            "Epoch 111: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 111: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 76s 777ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.6437 - val_accuracy: 0.8726\n",
            "Epoch 112/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9815\n",
            "Epoch 112: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 112: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0452 - accuracy: 0.9815 - val_loss: 0.6695 - val_accuracy: 0.8715\n",
            "Epoch 113/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9869\n",
            "Epoch 113: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 113: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 757ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.6787 - val_accuracy: 0.8670\n",
            "Epoch 114/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9850\n",
            "Epoch 114: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 114: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 76s 779ms/step - loss: 0.0520 - accuracy: 0.9850 - val_loss: 0.6371 - val_accuracy: 0.8704\n",
            "Epoch 115/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9780\n",
            "Epoch 115: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 115: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0644 - accuracy: 0.9780 - val_loss: 0.7010 - val_accuracy: 0.8715\n",
            "Epoch 116/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9636\n",
            "Epoch 116: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 116: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.1049 - accuracy: 0.9636 - val_loss: 0.6636 - val_accuracy: 0.8760\n",
            "Epoch 117/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9710\n",
            "Epoch 117: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 117: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 769ms/step - loss: 0.0984 - accuracy: 0.9710 - val_loss: 0.6965 - val_accuracy: 0.8682\n",
            "Epoch 118/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9841\n",
            "Epoch 118: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 118: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 755ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.6817 - val_accuracy: 0.8659\n",
            "Epoch 119/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9863\n",
            "Epoch 119: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 119: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0491 - accuracy: 0.9863 - val_loss: 0.7199 - val_accuracy: 0.8726\n",
            "Epoch 120/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9774\n",
            "Epoch 120: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 120: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 758ms/step - loss: 0.0613 - accuracy: 0.9774 - val_loss: 0.6331 - val_accuracy: 0.8715\n",
            "Epoch 121/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9774\n",
            "Epoch 121: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 121: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 0.6583 - val_accuracy: 0.8693\n",
            "Epoch 122/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9850\n",
            "Epoch 122: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 122: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 75s 770ms/step - loss: 0.0425 - accuracy: 0.9850 - val_loss: 0.6858 - val_accuracy: 0.8615\n",
            "Epoch 123/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9844\n",
            "Epoch 123: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 123: accuracy did not improve from 0.98693\n",
            "98/98 [==============================] - 73s 744ms/step - loss: 0.0561 - accuracy: 0.9844 - val_loss: 0.6403 - val_accuracy: 0.8827\n",
            "Epoch 124/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9901\n",
            "Epoch 124: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 124: accuracy improved from 0.98693 to 0.99011, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 75s 764ms/step - loss: 0.0272 - accuracy: 0.9901 - val_loss: 0.7195 - val_accuracy: 0.8670\n",
            "Epoch 125/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9796\n",
            "Epoch 125: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 125: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 752ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.5912 - val_accuracy: 0.8860\n",
            "Epoch 126/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9860\n",
            "Epoch 126: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 126: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 75s 769ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.6380 - val_accuracy: 0.8782\n",
            "Epoch 127/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9841\n",
            "Epoch 127: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 127: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 76s 775ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.7007 - val_accuracy: 0.8626\n",
            "Epoch 128/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9815\n",
            "Epoch 128: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 128: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 75s 761ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.6722 - val_accuracy: 0.8682\n",
            "Epoch 129/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9837\n",
            "Epoch 129: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 129: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.6920 - val_accuracy: 0.8749\n",
            "Epoch 130/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9857\n",
            "Epoch 130: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 130: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 758ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 0.8657 - val_accuracy: 0.8447\n",
            "Epoch 131/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9719\n",
            "Epoch 131: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 131: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 75s 768ms/step - loss: 0.0852 - accuracy: 0.9719 - val_loss: 0.6829 - val_accuracy: 0.8682\n",
            "Epoch 132/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9774\n",
            "Epoch 132: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 132: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.0647 - accuracy: 0.9774 - val_loss: 0.6350 - val_accuracy: 0.8659\n",
            "Epoch 133/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9754\n",
            "Epoch 133: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 133: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.0726 - accuracy: 0.9754 - val_loss: 0.6830 - val_accuracy: 0.8693\n",
            "Epoch 134/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9649\n",
            "Epoch 134: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 134: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 753ms/step - loss: 0.1080 - accuracy: 0.9649 - val_loss: 0.6826 - val_accuracy: 0.8682\n",
            "Epoch 135/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9825\n",
            "Epoch 135: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 135: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.0581 - accuracy: 0.9825 - val_loss: 0.5978 - val_accuracy: 0.8838\n",
            "Epoch 136/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9863\n",
            "Epoch 136: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 136: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 0.6645 - val_accuracy: 0.8771\n",
            "Epoch 137/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9793\n",
            "Epoch 137: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 137: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 73s 750ms/step - loss: 0.0598 - accuracy: 0.9793 - val_loss: 0.5798 - val_accuracy: 0.8771\n",
            "Epoch 138/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9895\n",
            "Epoch 138: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 138: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0437 - accuracy: 0.9895 - val_loss: 0.6340 - val_accuracy: 0.8771\n",
            "Epoch 139/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9853\n",
            "Epoch 139: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 139: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 73s 747ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.6016 - val_accuracy: 0.8827\n",
            "Epoch 140/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9777\n",
            "Epoch 140: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 140: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 75s 769ms/step - loss: 0.0556 - accuracy: 0.9777 - val_loss: 0.7525 - val_accuracy: 0.8704\n",
            "Epoch 141/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9799\n",
            "Epoch 141: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 141: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 76s 772ms/step - loss: 0.0663 - accuracy: 0.9799 - val_loss: 0.5936 - val_accuracy: 0.8849\n",
            "Epoch 142/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9793\n",
            "Epoch 142: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 142: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 753ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.6392 - val_accuracy: 0.8804\n",
            "Epoch 143/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9821\n",
            "Epoch 143: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 143: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 757ms/step - loss: 0.0535 - accuracy: 0.9821 - val_loss: 0.6133 - val_accuracy: 0.8737\n",
            "Epoch 144/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9885\n",
            "Epoch 144: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 144: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 76s 775ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.7641 - val_accuracy: 0.8525\n",
            "Epoch 145/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9780\n",
            "Epoch 145: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 145: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 77s 786ms/step - loss: 0.0639 - accuracy: 0.9780 - val_loss: 0.7122 - val_accuracy: 0.8682\n",
            "Epoch 146/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9601\n",
            "Epoch 146: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 146: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.1269 - accuracy: 0.9601 - val_loss: 0.8614 - val_accuracy: 0.8447\n",
            "Epoch 147/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9723\n",
            "Epoch 147: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 147: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 757ms/step - loss: 0.0689 - accuracy: 0.9723 - val_loss: 0.6946 - val_accuracy: 0.8626\n",
            "Epoch 148/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9863\n",
            "Epoch 148: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 148: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.6801 - val_accuracy: 0.8693\n",
            "Epoch 149/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9841\n",
            "Epoch 149: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 149: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.6070 - val_accuracy: 0.8827\n",
            "Epoch 150/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9850\n",
            "Epoch 150: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 150: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0454 - accuracy: 0.9850 - val_loss: 0.7571 - val_accuracy: 0.8525\n",
            "Epoch 151/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9847\n",
            "Epoch 151: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 151: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 75s 766ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.6701 - val_accuracy: 0.8603\n",
            "Epoch 152/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9872\n",
            "Epoch 152: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 152: accuracy did not improve from 0.99011\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0465 - accuracy: 0.9872 - val_loss: 0.7288 - val_accuracy: 0.8749\n",
            "Epoch 153/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9920\n",
            "Epoch 153: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 153: accuracy improved from 0.99011 to 0.99203, saving model to /content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.6564 - val_accuracy: 0.8804\n",
            "Epoch 154/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9869\n",
            "Epoch 154: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 154: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 74s 754ms/step - loss: 0.0346 - accuracy: 0.9869 - val_loss: 0.8019 - val_accuracy: 0.8615\n",
            "Epoch 155/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9857\n",
            "Epoch 155: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 155: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 74s 751ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.6490 - val_accuracy: 0.8816\n",
            "Epoch 156/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9876\n",
            "Epoch 156: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 156: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 73s 749ms/step - loss: 0.0254 - accuracy: 0.9876 - val_loss: 0.6576 - val_accuracy: 0.8793\n",
            "Epoch 157/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9892\n",
            "Epoch 157: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 157: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 73s 750ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.7708 - val_accuracy: 0.8615\n",
            "Epoch 158/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9751\n",
            "Epoch 158: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 158: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 73s 750ms/step - loss: 0.0824 - accuracy: 0.9751 - val_loss: 0.7607 - val_accuracy: 0.8793\n",
            "Epoch 159/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9809\n",
            "Epoch 159: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 159: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 74s 755ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 0.7339 - val_accuracy: 0.8659\n",
            "Epoch 160/160\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9876\n",
            "Epoch 160: val_accuracy did not improve from 0.88715\n",
            "\n",
            "Epoch 160: accuracy did not improve from 0.99203\n",
            "98/98 [==============================] - 74s 756ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.7883 - val_accuracy: 0.8670\n"
          ]
        }
      ],
      "source": [
        "filepath = \"/content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5\"\n",
        "filepath2 = \"/content/drive/MyDrive/defense/Accuracy/VGG19/highest_train2.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "checkpoint2 = ModelCheckpoint(filepath2, monitor='accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1,checkpoint2]\n",
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    epochs=160,\n",
        "    validation_data=val_set,\n",
        "    steps_per_epoch=len(training_set),\n",
        "    validation_steps=len(val_set),\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "model.save_weights(\"/content/drive/MyDrive/defense/Accuracy/VGG19/end2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "d4YJ6ZWYzeTE",
        "outputId": "12240fca-5bfa-44d6-df22-b0f162d97e7f"
      },
      "outputs": [],
      "source": [
        "#plot of accuracy and loss\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.title('Training and validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXCpE2LSzeVt",
        "outputId": "5ad45d62-0d10-4e50-aa9a-368b2f15413d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-11b330fb284d>:4: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  preds = model.evaluate_generator(test_set)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss = 0.36104530096054077\n",
            "Test Accuracy = 0.8736141920089722\n"
          ]
        }
      ],
      "source": [
        "#evaluating the model (test acc)\n",
        "#batch size = 32\n",
        "model.load_weights('/content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5')\n",
        "preds = model.evaluate_generator(test_set)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f6fEq-gjzeYp",
        "outputId": "d8fa223b-3b85-47aa-f210-3f60ed7979ac"
      },
      "outputs": [],
      "source": [
        "#confusion matrix\n",
        "\n",
        "#you have to set test bath size=1 before running the cell\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "model.load_weights('/content/drive/MyDrive/defense/Accuracy/VGG19/highest_val2.h5')\n",
        "filenames=test_set.filenames\n",
        "nb_samples=len(test_set)\n",
        "y_prob=[]\n",
        "y_act=[]\n",
        "test_set.reset()\n",
        "for _ in range (nb_samples):\n",
        "    X_test,Y_test = test_set.next()\n",
        "    y_prob.append(model.predict(X_test))\n",
        "    y_act.append(Y_test)\n",
        "predicted_class=[list(training_set.class_indices.keys())[i.argmax()] for i in y_prob]\n",
        "actual_class=[list(training_set.class_indices.keys())[i.argmax()]for i in y_act]\n",
        "out_df=pd.DataFrame(np.vstack([predicted_class,actual_class]).T,columns=['predicted_class','actual_class'])\n",
        "confusion_matrix=pd.crosstab(out_df['actual_class'],out_df['predicted_class'],rownames=['Actual'],colnames=['Predicted'])\n",
        "import matplotlib.pyplot as plt\n",
        "sn.heatmap(confusion_matrix,cmap=\"Greens_r\", annot=True, fmt='d')\n",
        "plt.show()\n",
        "#plt.savefig('/content/drive/MyDrive/model weights/vgg16_AugGfb_split1_maxval_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AauRco9jzefG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK6syvRlzeiF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfXByjLezelT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
