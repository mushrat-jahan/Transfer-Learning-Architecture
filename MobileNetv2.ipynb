{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDlf0jSXNQnH",
        "outputId": "85b001eb-141c-45f3-e7ae-e0a832d8e2f3",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul  2 14:08:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQpUg3t6fQDf",
        "outputId": "a8b5dea8-e3bb-42e0-c8c6-a31bc3dec44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W08KHUdoftOe",
        "outputId": "3bed6aed-ff50-4218-c912-52c7ea759b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.10/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Mnunng8e944",
        "outputId": "569a7440-d003-4ec6-8810-9cccba7df5a8"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "\n",
        "input_folder=\"/content/drive/MyDrive/Dataset/dataset2\"\n",
        "\n",
        "\n",
        "output=\"/content/\"\n",
        "\n",
        "\n",
        "splitfolders.ratio(input_folder, output, seed=42, ratio=(.80, .10, .10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPFoN_A6NWaO",
        "outputId": "951a9346-df0e-4d7d-944f-a5c1ca0218ab"
      },
      "outputs": [],
      "source": [
        "### model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "IMAGE_SIZE = [224,224]\n",
        "\n",
        "######################################### give class number ###########\n",
        "CLASS=4\n",
        "\n",
        "inception = MobileNetV2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "#model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#folders = glob('C:\\rafid\\guava disease research\\k_guava\\train_image/*')\n",
        "\n",
        "x = Flatten()(inception.output)\n",
        "\n",
        "prediction = Dense(CLASS, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inception.input, outputs=prediction)\n",
        "adam = keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=adam,\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.optimizer.get_config()\n",
        "print(\"\\n\\n\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnWaD7eDpZBT",
        "outputId": "11c683b0-239a-4372-a1ef-62aa81647222"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# sayma comment out line 2, Ritu comment out line 1 before running\n",
        "\n",
        "op = keras.optimizers.Adam(lr=0.001)  #for Sayma\n",
        "#op = keras.optimizers.Nadam(lr=0.0001)  # for Ritu\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=op,\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxoYAXL-Ncz2",
        "outputId": "f8f7f654-1027-4cc1-f9cf-ebda64ea4796"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  # shear_range = 0.2,\n",
        "                                  # zoom_range = 0.2,\n",
        "                                   brightness_range=(0.4, 0.7),\n",
        "                                   vertical_flip= True,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(r'/content/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "val_set = val_datagen.flow_from_directory(r'/content/val',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(r'/content/test',\n",
        "                                           target_size = (224,224),\n",
        "                                           batch_size = 1,\n",
        "                                           class_mode = 'categorical')\n",
        "\n",
        "\n",
        "\n",
        "model.optimizer.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUQmSIAGNgH2",
        "outputId": "6b902849-8236-4278-ec8a-8ba67157a65f"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "filepath = r\"/content/drive/MyDrive/Dataset/mobilenet/vgg16_s80.h5\"\n",
        "\n",
        "### example___filepath = \"path to weight directory/breastCancer_geometric.h5\"\n",
        "\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "log_csv = CSVLogger(r'/content/drive/MyDrive/Dataset/mobilenet/VGG16_s80.csv', separator=',', append=False)\n",
        "### example___CSVLogger('path to logs directory/breastCancer_geometric.csv')\n",
        "\n",
        "callbacks_list = [checkpoint1,log_csv]\n",
        "\n",
        "\n",
        "r = model.fit_generator(\n",
        "    training_set,\n",
        "    epochs=160,\n",
        "    validation_data=val_set,\n",
        "    steps_per_epoch = len(training_set),\n",
        "    validation_steps=len(val_set),\n",
        "    callbacks=callbacks_list,\n",
        "    shuffle=False\n",
        "\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcffk1wxSh6r",
        "outputId": "96849d3c-6172-4781-d62b-712ff93818ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-13-085658f506aa>:5: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  preds = model.evaluate_generator(val_set)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss =  4.617265224456787\n",
            "Test Accuracy =  92.76595711708069\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(r\"/content/drive/MyDrive/Dataset/mobilenet/vgg16_s80.h5\")\n",
        "Adam = keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "preds = model.evaluate_generator(val_set)\n",
        "print (\"Loss = \",float(preds[0]))\n",
        "print (\"Test Accuracy = \",float(preds[1])*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR8pMBs7e947",
        "outputId": "d914448b-d27c-4835-cae3-48399b996ef1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-14-ae91665d95db>:5: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  preds = model.evaluate_generator(test_set)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss =  4.8968377113342285\n",
            "Test Accuracy =  89.64059352874756\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(r\"/content/drive/MyDrive/Dataset/mobilenet/vgg16_s80.h5\")\n",
        "Adam = keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "\n",
        "preds = model.evaluate_generator(test_set)\n",
        "print (\"Loss = \",float(preds[0]))\n",
        "print (\"Test Accuracy = \",float(preds[1])*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "2OEq6DTQTI-H",
        "outputId": "b8e74579-b69f-44de-b678-60febd5d9592"
      },
      "outputs": [],
      "source": [
        "### loss and accuracy curve ### updated !!!!!!!!!!\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fin1= pd.read_csv(r'/content/drive/MyDrive/Dataset/mobilenet/VGG16_s80.csv') ###directory\n",
        "\n",
        "\n",
        "### accuracy curve ###\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(fin1['accuracy'], label='Trining accuracy')\n",
        "plt.plot(fin1['val_accuracy'], label='Validation accuracy')\n",
        "\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.savefig(r'D:\\Inam Ullah Khan\\RestNet50\\Zrms.png', dpi = 300)\n",
        "\n",
        "### loss curve ###\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(fin1['loss'], label='Trining loss')\n",
        "plt.plot(fin1['val_loss'], label='Validation loss')\n",
        "\n",
        "plt.title('Loss Curve')\n",
        "\n",
        "plt.savefig(r'D:\\Inam Ullah Khan\\RestNet50\\Zrms.png', dpi = 300)\n",
        "plt.legend(loc='upper right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ysg2LcakTVpA"
      },
      "outputs": [],
      "source": [
        "### for f1 score and other values import files ###\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### matrics\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frcIa6GpTa3N",
        "outputId": "50445f53-6a08-4322-be4c-1a1bd89ea0b7"
      },
      "outputs": [],
      "source": [
        "####predictions on test set\n",
        "\n",
        "y_test=[]\n",
        "probaa=[]\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "model.load_weights(r\"/content/drive/MyDrive/Dataset/mobilenet/vgg16_s80.h5\")\n",
        "\n",
        "\n",
        "cls=4  #nummber of classes\n",
        "\n",
        "## give directory of class serially..if less than 4 classes comment out the last unused dir_path\n",
        "dir_path1=r'/content/val/Botrytis Blight'\n",
        "dir_path2=r'/content/val/Downy Mildew'\n",
        "dir_path3=r'/content/val/Purple Blotch'\n",
        "dir_path4=r'/content/val/Stemphylium leaf blight'\n",
        "\n",
        "\n",
        "\n",
        "w1=0\n",
        "w2=0\n",
        "w3=0\n",
        "w4=0\n",
        "\n",
        "if cls==5:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path4):\n",
        "      img=image.load_img(dir_path4+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(3)\n",
        "      w4+=1\n",
        "      print(w4,end='_')\n",
        "\n",
        "  for filename in os.listdir(dir_path5):\n",
        "      img=image.load_img(dir_path4+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(3)\n",
        "      w4+=1\n",
        "      print(w4,end='_')\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "if cls==4:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path4):\n",
        "      img=image.load_img(dir_path4+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(3)\n",
        "      w4+=1\n",
        "      print(w4,end='_')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "\n",
        "if cls==2:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      #if res!=1: a2+=1\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))\n",
        "\n",
        "\n",
        "if cls==3:\n",
        "  for filename in os.listdir(dir_path1):\n",
        "      img=image.load_img(dir_path1+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(0)\n",
        "      w1+=1\n",
        "      print(w1,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path2):\n",
        "      img=image.load_img(dir_path2+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(1)\n",
        "      w2+=1\n",
        "      print(w2,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "  for filename in os.listdir(dir_path3):\n",
        "      img=image.load_img(dir_path3+'//'+filename, target_size=(224,224,3))\n",
        "      im = []\n",
        "      img = image.img_to_array(img)\n",
        "      img = img/255\n",
        "      im.append(img)\n",
        "      X= np.array(im)\n",
        "      result=model.predict(X,verbose=0)\n",
        "      #training_set.class_indices\n",
        "      res=np.argmax(result)\n",
        "      probaa.append(res)\n",
        "      y_test.append(2)\n",
        "      w3+=1\n",
        "      print(w3,end='_')\n",
        "\n",
        "  print('\\n')\n",
        "\n",
        "  print('class numbers', cls)\n",
        "  print('prediction number:',len(probaa))\n",
        "  print('true labels:',len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ion8W0t4ZJd3"
      },
      "outputs": [],
      "source": [
        "#We use Support Vector classifier as a classifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#importing packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "### matrics\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "hbPW9wdaZQVD",
        "outputId": "56e3a84d-2108-47c3-d627-212fca7dae63"
      },
      "outputs": [],
      "source": [
        "##  make a directory for storing figures\n",
        "y_preD=probaa\n",
        "cm = confusion_matrix(y_test, y_preD)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Botrytis Blight','Downy Mildew','Purple Blotch','Stemphylium leaf blight'],\n",
        "                     columns = ['Botrytis Blight','Downy Mildew','Purple Blotch','Stemphylium leaf blight'])\n",
        "\n",
        "#Plotting the confusion matrix\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm_df,cmap='cividis', annot=True, fmt='d')\n",
        "#plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "\n",
        "###save confusion matrix to fig directory ...keep the image file name as h5 file name. ex:  breastCancer_geometric.h5 >>> breastCancer_geometric_con.png\n",
        "plt.savefig(\"/content/drive/MyDrive/Dataset/mobilenet\\_s-(80)_con.png\", dpi = 300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1q92HMsZsYK",
        "outputId": "e48cffda-745d-4976-ab92-6e314e10320f"
      },
      "outputs": [],
      "source": [
        "y_preD=probaa\n",
        "y_val=y_test\n",
        "\n",
        "confusion_matrix=cm\n",
        "\n",
        "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "TP = np.diag(confusion_matrix)\n",
        "TN = len(y_val) - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from numpy import mean\n",
        "\n",
        "MAE=mean_absolute_error(y_val, y_preD)\n",
        "MSE=mean_squared_error(y_val, y_preD)\n",
        "F1=2*((mean(PPV)*mean(TPR))/(mean(PPV)+mean(TPR)))\n",
        "\n",
        "#print(\"ACC=   \",mean(ACC)*100)\n",
        "\n",
        "print(\"Rec=   \",mean(TPR)*100)\n",
        "print(\"Spe=   \",mean(TNR)*100)\n",
        "print(\"Pre=   \",mean(PPV)*100)\n",
        "print(\"FPR=   \",mean(FPR)*100)\n",
        "print(\"FNR=   \",mean(FNR)*100)\n",
        "print(\"NPV=   \",mean(NPV)*100)\n",
        "print(\"FDR=   \",mean(FDR)*100)\n",
        "print(\"F1=    \",mean(F1)*100)\n",
        "\n",
        "print(\"MAE   =\",MAE*100)\n",
        "print(\"RMSE  =\",math.sqrt(MSE)*100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWLo_fmAe949"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
